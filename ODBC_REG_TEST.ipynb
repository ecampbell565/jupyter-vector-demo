{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector ODBC Demo with sklearn and matplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and initialization\n",
    "We'll begin by importing the necessary libraries and initializing the fields that will be populated after a successful connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "\n",
    "property_data = {}\n",
    "obs_data = []\n",
    "\n",
    "# This dict will map numerical values to actual locations, in order to facilitate\n",
    "# the creation of the regression model\n",
    "location_mapping = {}\n",
    "\n",
    "# Used to fill location_mapping, unique for every different location\n",
    "location_id = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions\n",
    "We'll then define the following helper functions, paying special attention to the `plot_annual_averages` function which takes care of the actual plotting of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update the location mapping with the given string location, and return mapped numerical value\n",
    "def update_location_mapping(location):\n",
    "    global location_id\n",
    "    if(location in location_mapping):\n",
    "        return location_mapping[location]\n",
    "    location_mapping[location] = location_id\n",
    "    location_id += 1\n",
    "    return location_mapping[location]\n",
    "\n",
    "# Generate test points for an integer number of years\n",
    "def generate_test_points(years):\n",
    "    test_points = []\n",
    "    current_year = 2017\n",
    "    end_year = current_year + years\n",
    "    for year in range(current_year, end_year):\n",
    "        for loc_string, loc_id in location_mapping.iteritems():\n",
    "            test_points.append([year, loc_id])\n",
    "    return test_points\n",
    "\n",
    "# Given a dict data with field 'input'=[[year, location],...] and 'output' = [obs_value,...]\n",
    "# return an average obs_value per year as a dict with key year and value obs_value\n",
    "def average_over_locations(data):\n",
    "    sums = {}\n",
    "    counts = {}\n",
    "    averages = {}\n",
    "    for i in range(0, len(data['input'])):\n",
    "        data_point = data['input'][i]\n",
    "        year = str(data_point[0])       # convert year to string to use as key\n",
    "        if(year in sums):\n",
    "            sums[year] += data['output'][i]\n",
    "            counts[year] += 1\n",
    "        else:\n",
    "            sums[year] = data['output'][i]\n",
    "            counts[year] = 1\n",
    "    for year in sums:\n",
    "        averages[year] = sums[year]/counts[year]\n",
    "    return averages\n",
    "\n",
    "# Given a dict with key year and value average obs_value, produce a bar graph\n",
    "def plot_annual_averages(averages, ylabel, title):\n",
    "    #averages.sort(key=lambda x: x.count, reverse=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    years = []\n",
    "    avg_vals = []\n",
    "    for year, avg_obs in averages.iteritems():\n",
    "        years.append(year)\n",
    "        avg_vals.append(avg_obs)\n",
    "    years = tuple(years)\n",
    "    y_pos = np.arange(len(years))\n",
    "    ax.bar(y_pos, avg_vals)\n",
    "    plt.bar(y_pos, avg_vals)\n",
    "    plt.xticks(y_pos, years)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    ax.tick_params(axis='x', which='major', pad=15)\n",
    "    plt.show()\n",
    "\n",
    "# Given two dicts, merge them into a new dict as a shallow copy.\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot_annual_averages` function simply accepts and formats a data parameter, as well as several self-explanatory chart parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the instance\n",
    "We will now connect to the Vector instance using `pyodbc.connect()`\n",
    "DSN refers to the Data Source that was created earlier, and this simply query pulls the row data that will be needed for the regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize connection and query\n",
    "cnxn = pyodbc.connect('DSN=initial_attempt;uid=ecampbell;pwd=Javascript@110')\n",
    "cursor = cnxn.cursor()\n",
    "query = 'SELECT year, location, indicator, obs_value FROM international_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the data returned from cursor.execute()\n",
    "Because `cursor.execute()` returns an iterable, we can use a simple for loop to iterate over the rows returned by the queries above, parsing them into the necessary formats for sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterate over row data\n",
    "for row in cursor.execute(query):\n",
    "    year = int(row.year)\n",
    "    obs_value = round(float(row.obs_value))\n",
    "    location = update_location_mapping(row.location)\n",
    "\n",
    "    # Update the property data for each type of indicator\n",
    "    if(row.indicator in property_data):\n",
    "        property_data[row.indicator]['input'].append([year, location])\n",
    "        property_data[row.indicator]['output'].append(obs_value)\n",
    "    else:\n",
    "        property_data[row.indicator] = {'input': [[year, location]], 'output': [obs_value]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classification model\n",
    "Once the data has been properly formatted, we train the classification model provided by the `OneVsRestClassifier` class from sklearn, and then feed in the test points generated with future `year` values to predict the chosen index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare test points in order to produce a predictive model\n",
    "test_data = generate_test_points(5)\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "predictive_output = classif.fit(input_data, target_data).predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying calculated data\n",
    "Now that we have all our data from the regression model, we'll use it to calculate the average index across all countries for each given year and display these values using matplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate averages across all years\n",
    "averages = merge_two_dicts(average_over_locations(property_data[indicator]),\n",
    "        average_over_locations({\n",
    "            'input': test_data,\n",
    "            'output': predictive_output\n",
    "        }))\n",
    "# Plot averages\n",
    "plot_annual_averages(averages, 'OBS Value', 'Intellectual Property Rights Index by Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full python script has been provided below for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyodbc\n",
    "\n",
    "property_data = {}\n",
    "obs_data = []\n",
    "\n",
    "# This dict will map numerical values to actual locations, in order to facilitate\n",
    "# the creation of the regression model\n",
    "location_mapping = {}\n",
    "\n",
    "# Used to fill location_mapping, unique for every different location\n",
    "location_id = 1\n",
    "\n",
    "# Update the location mapping with the given string location, and return mapped numerical value\n",
    "def update_location_mapping(location):\n",
    "    global location_id\n",
    "    if(location in location_mapping):\n",
    "        return location_mapping[location]\n",
    "    location_mapping[location] = location_id\n",
    "    location_id += 1\n",
    "    return location_mapping[location]\n",
    "\n",
    "# Generate test points for an integer number of years\n",
    "def generate_test_points(years):\n",
    "    test_points = []\n",
    "    current_year = 2017\n",
    "    end_year = current_year + years\n",
    "    for year in range(current_year, end_year):\n",
    "        for loc_string, loc_id in location_mapping.iteritems():\n",
    "            test_points.append([year, loc_id])\n",
    "    return test_points\n",
    "\n",
    "# Given a dict data with field 'input'=[[year, location],...] and 'output' = [obs_value,...]\n",
    "# return an average obs_value per year as a dict with key year and value obs_value\n",
    "def average_over_locations(data):\n",
    "    sums = {}\n",
    "    counts = {}\n",
    "    averages = {}\n",
    "    for i in range(0, len(data['input'])):\n",
    "        data_point = data['input'][i]\n",
    "        year = str(data_point[0])       # convert year to string to use as key\n",
    "        if(year in sums):\n",
    "            sums[year] += data['output'][i]\n",
    "            counts[year] += 1\n",
    "        else:\n",
    "            sums[year] = data['output'][i]\n",
    "            counts[year] = 1\n",
    "    for year in sums:\n",
    "        averages[year] = sums[year]/counts[year]\n",
    "    return averages\n",
    "\n",
    "# Given a dict with key year and value average obs_value, produce a bar graph\n",
    "def plot_annual_averages(averages, ylabel, title):\n",
    "    #averages.sort(key=lambda x: x.count, reverse=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    years = []\n",
    "    avg_vals = []\n",
    "    for year, avg_obs in averages.iteritems():\n",
    "        years.append(year)\n",
    "        avg_vals.append(avg_obs)\n",
    "    years = tuple(years)\n",
    "    y_pos = np.arange(len(years))\n",
    "    ax.bar(y_pos, avg_vals)\n",
    "    plt.bar(y_pos, avg_vals)\n",
    "    plt.xticks(y_pos, years)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "    ax.tick_params(axis='x', which='major', pad=15)\n",
    "    plt.show()\n",
    "\n",
    "# Given two dicts, merge them into a new dict as a shallow copy.\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "# Initialize connection and query\n",
    "cnxn = pyodbc.connect('DSN=initial_attempt;uid=ecampbell;pwd=Javascript@110')\n",
    "cursor = cnxn.cursor()\n",
    "query = 'SELECT year, location, indicator, obs_value FROM international_data'\n",
    "\n",
    "# Iterate over row data\n",
    "for row in cursor.execute(query):\n",
    "    year = int(row.year)\n",
    "    obs_value = round(float(row.obs_value))\n",
    "    location = update_location_mapping(row.location)\n",
    "\n",
    "    # Update the property data for each type of indicator\n",
    "    if(row.indicator in property_data):\n",
    "        property_data[row.indicator]['input'].append([year, location])\n",
    "        property_data[row.indicator]['output'].append(obs_value)\n",
    "    else:\n",
    "        property_data[row.indicator] = {'input': [[year, location]], 'output': [obs_value]}\n",
    "\n",
    "# Although there's several indicators, we're going to stick with just graphing one\n",
    "indicator = 'Intellectual Property Rights, Overall (Global Rank)'\n",
    "input_data = property_data[indicator]['input']\n",
    "target_data = property_data[indicator]['output']\n",
    "\n",
    "# Prepare test points in order to produce a predictive model\n",
    "test_data = generate_test_points(5)\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "predictive_output = classif.fit(input_data, target_data).predict(test_data)\n",
    "\n",
    "# Calculate averages across all years\n",
    "averages = merge_two_dicts(average_over_locations(property_data[indicator]),\n",
    "        average_over_locations({\n",
    "            'input': test_data,\n",
    "            'output': predictive_output\n",
    "        }))\n",
    "plot_annual_averages(averages, 'OBS Value', 'Intellectual Property Rights Index by Year')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
